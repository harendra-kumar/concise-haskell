Recursion
=========

.. contents:: Table of Contents
   :depth: 1

Terminology
-----------

+------------------------+----------------------------------------------------+
| Converge               | An iterative series that ends in a constant value  |
|                        | or a recursive computation that ultimately ends is |
|                        | said to converge                                   |
+------------------------+----------------------------------------------------+
| Diverge                | An iterative series or a recursive computation     |
|                        | that never ends is said to diverge.                |
|                        | A partial function is said to diverge when it is   |
|                        | invoked for an undefined value.                    |
+------------------------+----------------------------------------------------+
| Algebra                | A set of values (the carrier set) along with the   |
|                        | operations on the set                              |
+------------------------+----------------------------------------------------+
| Initial algebra        | Defined by the fact that there is always a         |
|                        | unique homomorphism from the initial algebra to an |
|                        | arbitrary algebra                                  |
+------------------------+----------------------------------------------------+
| Final algebra          | there is a unique homomorphism from an arbitrary   |
|                        | algebra to a final algebra. Also called terminal   |
|                        | algebra.                                           |
+------------------------+----------------------------------------------------+
| Induction              | Use of initiality for algebras                     |
+------------------------+----------------------------------------------------+
| Coinduction            | Use of finality for algebras                       |
+------------------------+----------------------------------------------------+
| F-Algebra              | An algebra of a functor type                       |
+------------------------+----------------------------------------------------+
| T-Algebra              | An algebra of a monad type                         |
+------------------------+----------------------------------------------------+

Algebra and Coalgebra
---------------------

Mathematically an algebra consists of a set and functions or operations on the
members of the set conforming to certain rules. For Haskell the set could be a
type or types. The types combined with functions on them constitues of an
algebra.

Every algebraic data type has an algebra associated with it. A functor type can
have many algebras associated with it but there is a unique initial algebra.
Recursive algebraic data types can be categorised in two distinct classes,
defined by an algebra or a coalgebra.

Algebra
~~~~~~~

Algebraic structures are defined by `constructor operations`. For example,
natural numbers or finite lists and trees.  Formally they are initial algebras.
An initial algebra can be obtained from closed terms i.e. from those terms
which are generated by iteratively applying the algebra's constructor
operations.

Induction is used as a definition principle and as proof principle for such
structures.  In an inductive definition of a function f, one defines the value
of f on all constructors.

A finite list is an inductive data type, defined by the initial algebra of a
functor::

  data List a  = Empty | Cons a (List a)

A recursive data has an initial constructor (the base case) and a building
constructor.  Therefore a recursive function can do the opposite i.e. dismantle
the recursive constructor and finally reach the base case.

Coalgebra
~~~~~~~~~

The dual notion of an algebra (of a functor) is a coalgebra (of a functor).
Coalgebraic structures are defined by `destructor operations`.  Destructor
operations are also called observers, accessors, transition maps, or mutators.
Formally, they are terminal coalgebras. A terminal coalgebra can be obtained
from pure observations.

Coinduction is used as a definition principle and as proof principle for such
structures.  In a coinductive definition of a function f, one defines the
values of all destructors on each outcome f(x).

Suppose next, that we wish to define an operation even which takes an infinite
list, and produces a new infinite list which contains (in order) all the
elements occurring in evenly numbered places of the original list. That is, we
would like the operation even to satisfy::

  even(σ(0), σ(1), σ(2), . . .) = (σ(0), σ(2), σ(4), . . .) (1.3)

A little thought leads to the following definition clauses::

  head(even(σ)) = head(σ)
  tail(even(σ)) = even(tail(tail(σ)))

Coalgebras often describe dynamical systems (of some sort). For example,
streams or processes.

Recursive (data) and corecursive data (codata)
----------------------------------------------

The structure of a data object is exposed, while
the structure of a codata object is hidden.

Unlike a data object, a codata object does not
have the attributes ordinarily associated with a
"value". The show function is not defined on a
codata object; codata cannot belong to the Eq
class; there are no derived methods on a codata
ob ject.

A data object has open access, as its structure
is visible. A codata object has only the access
methods specified by its declaration. These
methods comprise a set of typed functions, some
of which yield data values when invoked, and
some of which may yield a new codata object.

Data objects are usually finitary (lazily evaluated
recursive data structures are an exception
to this rule) while codata objects are usually in-
finitary (finite records are an exception to this
rule).

`The Producer Contract:` The producer of data promises that he/she will
construct data only `using the agreed constructors`.

`The Consumer contract`: The consumer of codata promises that he/she will only
analyze codata `using the patterns` induced by the agreed constructors.

+-------------------------------------+---------------------------------------+
| data                                | codata                                |
+=====================================+=======================================+
| Defined in terms of constructors    | Defined in terms of destructors       |
+-------------------------------------+---------------------------------------+
| Pattern matching                    | Constructor generation                |
| (Constructor elimination)           |                                       |
+-------------------------------------+---------------------------------------+
| The producer contract               | The consumer contract                 |
+-------------------------------------+---------------------------------------+
| Initial algebras                    | Terminal coalgebras                   |
+-------------------------------------+---------------------------------------+
| inductive                           | coinductive                           |
+-------------------------------------+---------------------------------------+
| finite objects                      | infinite objects                      |
+-------------------------------------+---------------------------------------+
| structural recursion                | guarded corecursion                   |
+-------------------------------------+---------------------------------------+
| structural induction                | guarded coinduction                   |
+-------------------------------------+---------------------------------------+

Functions are mappings which can map data to data or codata, and codata to
data or codata. They create abstractions which can be used to abstract data or
codata. data and codata are two different ways of looking at some state.
Functions just help abstract any of those representations.

When are these conversions useful?

  * data   <-> data
  * data   <-> codata
  * codata <-> data
  * codata <-> codata


When we use a function to represent codata, the function output has to be
closed with respect to the data type i.e. it must generate constructors of that
one data type only.

Data incrementally builds up a complex structure from primitive constructors.
codata starts from a prebuilt complex structure and manipulates it based on its
components as inputs. In other words in data we approach from the initial
state, while in codata we approach from the final state.

`Where we start?`: For data we start with functions and build up constructors
by accepting primtive constructors. For codata we start with constructors and
change it by using functions.

In codata a function works from inside the data representation whereas in data
it works from outside the data representation.  data always starts from the
same initial primitives and can end up in many different structures. codata
always ends up in the same final data structure and can change it based on any
components of it. codata looks at data as a whole whereas data looks at data as
sum of its parts.

coalgebras are therefore suitable to represent continuous infinite processes,
moving from one state to another. algebras on the other are suitable to
represent finite data structures.

codata is a closed structure like infinitely nested eggs and we work on it from
outside, we keep peeling layers from outside. recursive data is an open
recursive structure like a tree which we can build or dismantle piece by piece.
codata and data are just opposite. in data we start building from the smallest
pieces and keep on building, we can go on till infinity but whenever we stop,
it will be finite. In the case of codata we start from the other end of the
spectrum i.e. (a prebuilt infinite structure) infinity and keep removing
layers. Since it is infinite, it never ends whatever number of layers we remove
from it.

A recursive structure always has a base case since we always start building
from the base up. When we dismantle it we finally reach the base case. A
corecursive structure always has the final or terminal case. We never build a
corecursive structure, it starts from the whole. We always start consuming it
from the terminal case, and we can never dismantle it completely.

In Haskell, data and codata both are defined in the same way, there is no type
level distinction:

* recursive data is usually a sum type because we need a base case to build
  upon. `data A a = Base a | Recurse a (A a)` . canonical example is a list.
* corecursive structure is usually a product type `data A a = Y (A a)` because
  there is no base case and we start from the final case itself. canonical
  example is a stream.

Recursive and Corecursive Procedures
------------------------------------

Recursion expresses a well defined pattern. We just specify a rule to govern
the repetitive pattern. When we use a rule to consume a recursively defined
data structure , and reduce it to a non-recursive data structure, it is called
recursion. When we use a rule to generate a recursive data structure from a
non-recursive seed structure, it is called corecursion.

* Recursion consumes recursive data structures in a pattern
* Corecursion produces a pattern of recursive data structures

+-------------------------------------+---------------------------------------+
| Recursion                           | Corecursion                           |
+=====================================+=======================================+
| consume                             | produce                               |
+-------------------------------------+---------------------------------------+
| fold                                | unfold                                |
+-------------------------------------+---------------------------------------+
| dismantle                           | build                                 |
+-------------------------------------+---------------------------------------+
| Driven by a function                | Driven by a constructor               |
+-------------------------------------+---------------------------------------+
| Finite                              | Infinite                              |
+-------------------------------------+---------------------------------------+
| data                                | codata                                |
+-------------------------------------+---------------------------------------+
| algebra                             | coalgebra                             |
+-------------------------------------+---------------------------------------+
| Mealy machine                       | Moore machine                         |
+-------------------------------------+---------------------------------------+
| Monad                               | Comonad                               |
+-------------------------------------+---------------------------------------+

Note the duality: in structural recursion we 'deconstruct' the argument and
then we're allowed to recurse. In guarded recursion we recurse first, and then
we're allowed to use the constructor.

The rule is: you're only allowed to use structural recursion with data and
guarded recursion with codata. With that rule, we're guaranteed that our
recursions will always be safe, and yet that we can still have open-ended loops
in our code. Sometimes these are called recursion and corecursion respectively.

Recursive Expressions
---------------------

An expression can be defined recursively by referring to the value being
defined within the definition.  Any recursive definition can be reduced to the
following normalized version::

  x = f x -- implies f :: a -> a

When `f` is a function that performs a case analysis on `x` we have a
structural recursion which eliminates the structure of `x`. When `f` is a
constructor of `x` instead that is expressed in terms of functions of `x` then
we have a corecursion that builds an infinite codata. Notice that whether `f`
is a constructor or function its return type must always be the same as the
type of `x`.

We can see `x` unfold clearly by repeatedly substituting the term `x` in the
expression for its own definition::

  f x
  f (f x)           -- after substituting x by (f x)
  f (f (f x))       -- after substituting x by (f x)
  ...

This is in fact how we defined iteration earlier i.e. applying a function
repeatedly on the previous result. Though we do not have much control over it.

In the following discussion we assume that `f` is strict in `x`. If `f`
discards `x` then the definition just reduces to a trival non-recursive one.
For example::

    x = f x where f = const 10 -- x = 10

Structural Recursion (Recursion)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When the function `f` in `x = f x` performs a case analysis on `x` (or
application of `x` when it is a function) before constructing an output we have
a recursive expression.

Recursive Data Expressions
^^^^^^^^^^^^^^^^^^^^^^^^^^

When `x` is of concrete type and not a function, evaluation of `x = f x` where
`f` scrutinizes `x`, results in an infinite loop.  Any side effects before the
scrutiny of `x` are produced in the loop. For example:

* `f` just scrutinizes `x`::

    -- infinite loop
    x = x     -- x = _|_
    x = x + 1 -- x = _|_
    x = id x  -- x = _|_

* `f` produces side effects before it scrutinizes `x`::

    -- prints "yes" in infinite loop
    x = putStrLn "yes" >> x >> putStrLn "no"

Recursive Functions
^^^^^^^^^^^^^^^^^^^

A recursive function can either iterate application of a function on a
non-recursive data or it can eliminate and fold a recursive data structure.

A recursive definition can also be called an inductive definition of a
function.

Recursion with functions is quite common and therefore familiar to most
programmers.  Let us write a simple recursive function that finds the fixed
point of `sqrt`::

  fixSqrt x =
      case (sqrt x == x) of
        True -> x
        False -> fixSqrt (sqrt x)

  >> fixSqrt 256
  1.0

When we evaluate `fixSqrt 256`, it results in a call to `fixSqrt 16` in the
first step and then `fixSqrt 4` in the next step, and so on. Finally when the
argument `x` passed to `fixSqrt` becomes very close to 1 then we hit the `True`
case and the value gets evaluated to `x` i.e. 1.0.

For termination, a recursive function must have a case where it does not
recurse further. Even then it is possible that it never hits the termination
condition.

Some more examples of structural recursion::

  sum [] = 0
  sum (a:as) = a + sum as

  fact 0 = 1
  fact n = n * fact (n-1)

  data Nat = Zero | S Nat

  -- using n+k patterns
  fact' 0 = 1
  fact' (n+1) = (n+1) * fact' n

Guarded corecursion (Corecursion)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

When the function `f` in `x = f x` constructs `x` before a case analysis on `x`
(or application of `x` when it is a function) we have a corecursive expression
generating an infinite codata. This means the outermost application `f` is a
constructor of `x` represented in terms of functions of x. Notice that this is
dual of a regular case analysis based function implementation.

Corecursive Data Expressions
^^^^^^^^^^^^^^^^^^^^^^^^^^^^

When `f` is a data constructor of `x` in `x = f x`, the expression evaluates to
a lazy infinite codata structure.  The data type of `x` has to be necessarily
recursively defined; for this expression to typecheck in this case.

Let us see some examples:

* infinite lazy codata construction::

    let x = 1 : x in take 10 x
    let x = 1 : 2 : 3 : x in take 10 x

    data X = Cons X Int
    let x = Cons x 1
    in let Cons y 1 = x
           Cons z 1 = y
           ...

* The constructor `f` can be defined in terms of a function of `x` returning
  the same data type::

    let fibs = 1 : 1 : zipWith (+) fibs (tail fibs) in take 10 fibs

Co-recursive computations can be expressed in terms of recursive ones:

::

  -- cyclic list
  -- unfoldr is however implemented using corecursion!
  unfoldr (\x -> Just (x, x)) 1


Constructor function constructor => corecursion
function constructor function    => recursion

Co-recursion and recursion are two different ways of expressing. We can
accomplish a task in any of the ways but some tasks are more sutiable to one
form than the other.

Similarly, at another level, recursive and iterative are two different ways to
accomplish a task. Any of them can be employed to accomplish a task. Both
recursion and co-recursion can be expressed in iterative manner.

Corecursive Functions
^^^^^^^^^^^^^^^^^^^^^

If `f` is a constructor in the expression `g = f g` or equivalently `g x = f g
x` then the constructor `f` has to be necessarily recursively defined because
`f` is recursively defined in terms of `g` which returns the same type as `f`.

In general, `g` pattern matches and breaks down `x`, which is in WHNF already
because the top level is necessarily a constructor, and defines `f` in terms of
the components of `x`.

In fact the function `g` is not recursive in real sense because it does not
really case analyze anything, the pattern match on LHS is trivial as the data
is guaranteed to be in WHNF, the only thing it is doing is to connect the
components of `f` on both sides.

This is dual to the recursive functions where the function is recursive but the
data it uses does not have to be. Here the data is recursive but the functions
used by it do not have to be.

Corecursive definition can also be called a coinductive definition of a
function.

Transform a stream::

  showStream (x:xs) = show x : showStream xs

Sum of a stream::

  sumSoFar x [] = [x]

  -- the second argument is corecursive so we can keep pattern matching on it
  sumSoFar x (y:ys) = x : sumSoFar (x+y) ys

A corecursive definition starts from a concrete seed, it remembers the
previous value and builds the next value using the previous values::

  x2 = x1 + ...
  x3 = x2 + ...
  x4 = x3 + ...

It is essentially a builder. It has a seed and a builder::

  builder (x, y : ys) = Just (x + y, (x + y, ys))
  unfoldr builder (0, (let x = 1 : x in x))

Iteration
---------

Iteration and Fixed Point
~~~~~~~~~~~~~~~~~~~~~~~~~

Iteration of a function is defined as applying the function repeatedly to its
previous result.  As an example, we can apply `sqrt` to a number iteratively::

  takeWhile (/= 1) $ iterate sqrt 2

`sqrt` converges to 1 if we keep iterating it starting with any number. 1 is
called the fix-point of sqrt. In general when `c = f c`, `c` is called the fix
point of a function.

Recursion versus iteration
~~~~~~~~~~~~~~~~~~~~~~~~~~

Recursion and iteration are equally expressive: recursion can be replaced by
iteration with an explicit stack, while iteration can be replaced with tail
recursion.

Which approach is preferable depends on the problem under consideration and the
language used. In imperative programming, iteration is preferred, particularly
for simple recursion, as it avoids the overhead of function calls and call
stack management, but recursion is generally used for multiple recursion. By
contrast, in functional languages recursion is preferred, with tail recursion
optimization leading to little overhead, and sometimes explicit iteration is
not available.

Iterative Wrapper for Recursion
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If we look carefully the body of `fixSqrt` is a function of `fixSqrt` and `x`
the argument, we can write it explicitly in terms of a function `f` that is a
function of `fixSqrt` and `x` the argument of `fixSqrt`. If we rename `fixSqrt`
to `g` instead, we can write it as::

  g = f g
    where
      f g x =
          case (sqrt x == x) of
            True -> x
            False -> g (sqrt x)

Notice this is exactly the same as the general recursive expression `x = f x`
that we discussed earlier.  In fact, any recursive function can be expressed in
this form.

Also notice that `f` is not a recursive function.  We can read `f` as "check if
x is the same as `sqrt x`, if not call the function `g` on on `sqrt x` i.e.
perform the next iteration", there is no recursion.  `f` just represents one
step or a single iteration in the recursion process.

The explicit recursion is limited to the expression `g = f g`. As we saw
earlier this expression is equivalent to applying `f` iteratively over `g`.
However unlike concrete values the result of every iteration is a function
which may terminate when applied.

As a note, just like recursion did not make sense in case of concrete values,
corecursion does not make sense for functions as cannot be constructed using
data constructors.

Recursive Functions as fixed points (fix)
-----------------------------------------

We can define recursion as a fixed point of functions. We iterate over a
non-recursively defined function to derive each step of the recursion. In other
words we perform recursion by iteration or we can also call it definitional
recursion.

We can write a utility function to iterate with a function `f`, we will call it
`fix`::

  fix :: (a -> a) -> a
  fix f = let x = f x in x

Examples
~~~~~~~~

::

  -- corecursion
  f x = 1 : 1 : zipWith (+) x (tail x)
  take 10 (fix f)

  -- recursion
  f g x =
      case (sqrt x == x) of
        True -> x
        False -> g (sqrt x)
  fix f 10

Notice that if you simply remove the `f` from the definitions above you will
get the recursive definitions.

The Y-Combinator
~~~~~~~~~~~~~~~~

fix is also called the fixed-point combinator or the Y combinator in lambda
calculus discovered by Haskell B. Curry::

  fix f = f (fix f)                -- Lambda lifted
  fix f = let x = f x in x         -- Lambda dropped

Recursive Data as fixed points (Fix)
------------------------------------

A recursive container is not only a functor but it can also be defined as a
fixed point of a functor.

* Just like recursive functions are defined as fixed points of regular
  functions, recursive (nested) data structures can be defined as fixed points
  of regular type constructors.
* Functors are interesting type constructors because they give rise to nested
  data structures that support recursive evaluation (generalized folding).
* An F-algebra is defined by a functor `f`, a carrier type `a`, and a function
  from `f a` to `a`.

::

  newtype Fix f = In (f (Fix f))

This is has the same pattern as our `x = f x` equation if we substitue `x` for
`Fix f`. Also, very similar to the `fix f = f (fix f)`. Here `f` is a functor
instead of a function.

Just like `g = f g` represents pure recursion for functions, `t = f t`
represents pure recursion for data types. Here `t` is a type function and `f`
is a functor.

Recursion Schemes
-----------------

Recursion schemes are higher level constructs to abstract the structure of
recursion. They provide a higher level language (algebras and coalgebras) to
express common patterns of recursion in a convenient manner hiding boilerplate
under the hood.

Given a recursive data structure (or nested boxes of constructors) we want to
fold the structure in some way. The structure is represented as a functor, for
example from type `a` to `f a` (e.g. from Int to [Int]). An algebra provides
rules to reverse map from `f a` to `a`. Given the algebra and the structure we
can fold the structure back to `a`.

For example a `catamorphism` is one such fold::

  cata :: Functor f => (f a -> a) -> (Fix f -> a)

There are list examples in:
https://www.schoolofhaskell.com/user/bartosz/understanding-algebras

Summary of Recursion Schemes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

::

  Recursive data     -----> recursive function   ----> non-recursive data
  finite codata      -----> catamorphism         ----> data
                            tear "down"

  Non-recursive data -----> corecursive function ----> recursive data
  data               -----> anamorphism          ----> possibly infinite codata
                            build "up"

  recursive data     ------> cata + ana  = meta  ----> recursive data
  non-recursive data ------> ana  + cata = hylo  ----> non-recursive data

  recursion   -----> algebra   + recursion scheme
  corecursion -----> coalgebra + recursion scheme


Hylomorphism
~~~~~~~~~~~~

::

  import Data.Functor.Foldable
  import Data.List (splitAt, unfoldr)

  data TreeF c f = EmptyF | LeafF c | NodeF f f
    deriving (Eq, Show, Functor)

  mergeSort :: Ord a => [a] -> [a]
  mergeSort = hylo alg coalg where
    alg EmptyF      = []
    alg (LeafF c)   = [c]
    alg (NodeF l r) = merge l r

    coalg []  = EmptyF
    coalg [x] = LeafF x
    coalg xs  = NodeF l r where
      (l, r) = splitAt (length xs `div` 2) xs

  merge :: Ord a => [a] -> [a] -> [a]
  merge = curry $ unfoldr c where
    c ([], [])     = Nothing
    c ([], y:ys)   = Just (y, ([], ys))
    c (x:xs, [])   = Just (x, (xs, []))
    c (x:xs, y:ys) | x <= y = Just (x, (xs, y:ys))
                   | x > y  = Just (y, (x:xs, ys))

Mutual Recursion
----------------

::

  x = f y
  y = g x

References
----------

* Recursion, traversal & folds are related
* https://en.wikipedia.org/wiki/Fixed-point_combinator

* https://en.wikipedia.org/wiki/Primitive_recursive_function
* https://en.wikipedia.org/wiki/Recursion_(computer_science)
* https://en.wikipedia.org/wiki/Corecursion
* https://www.schoolofhaskell.com/user/bartosz/understanding-algebras
* https://bartoszmilewski.com/2014/01/28/you-cant-make-an-algebra-without-breaking-a-few-eggs/
* http://stackoverflow.com/questions/6941904/recursion-schemes-for-dummies

* http://homepages.cwi.nl/~janr/papers/files-of-papers/2011_Jacobs_Rutten_new.pdf New version of the tutorial
* http://www.cs.ru.nl/~bart/PAPERS/JR.pdf A tutorial on (co)algebras and (co)induction, Bart Jacobs
* http://www.tac-tics.net/blog/data-vs-codata
* http://blog.sigfpe.com/2007/07/data-and-codata.html
* http://types2004.lri.fr/SLIDES/altenkirch.pdf codata - Thorsten Altenkirch, University of Nottingham
* http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.46.5169&rep=rep1&type=pdf Codata and Comonads in Haskell
* http://www.cs.ox.ac.uk/ralf.hinze/publications/CEFP09.pdf Reasoning about Codata
* http://stackoverflow.com/questions/28841260/what-is-the-difference-between-codata-and-data
* http://lambda-the-ultimate.org/node/4373 Data, Codata, and Their Implications for Equality, and Serialization

Recursion schemes:

* http://blog.sumtypeofway.com/an-introduction-to-recursion-schemes/
* https://medium.com/@jaredtobin/practical-recursion-schemes-c10648ec1c29#.9lij6s5a8 On Kmett's recursion scheme library (has a good mergesort example)
* https://jozefg.bitbucket.io/posts/2014-05-19-like-recursion-but-cooler.html? On Kmmet's recursion schemes
* http://comonad.com/reader/2009/recursion-schemes/
* https://hackage.haskell.org/package/recursion-schemes
* http://fho.f12n.de/posts/2014-05-07-dont-fear-the-cat.html
* https://www.schoolofhaskell.com/user/edwardk/recursion-schemes/catamorphisms
* https://ulissesaraujo.wordpress.com/2009/04/09/hylomorphisms-in-haskell/
* https://ulissesaraujo.wordpress.com/2009/04/09/more-hylomorphisms-in-haskell/
* https://github.com/willtim/recursion-schemes/raw/master/slides-final.pdf

  * https://www.youtube.com/watch?v=Zw9KeP3OzpU Talk video

* https://en.wikipedia.org/wiki/Category:Recursion_schemes
* https://en.wikipedia.org/wiki/Catamorphism generalizations of folds of lists to arbitrary algebraic data types
* https://en.wikipedia.org/wiki/Anamorphism Dual of catamorphism - unfold
* https://en.wikipedia.org/wiki/Paramorphism extension of catamorphism “eats its argument and keeps it too”
* https://en.wikipedia.org/wiki/Apomorphism Dual of paramorphsim
* https://en.wikipedia.org/wiki/Hylomorphism_(computer_science) anamorphism followed by a catamorphism

* http://cgi.csc.liv.ac.uk/~grant/PS/thesis.pdf Algebraic Data Types and Program Transformation
* http://dl.acm.org/citation.cfm?id=2034807 A hierarchy of mendler style recursion combinators: taming inductive datatypes with negative occurrences".

* https://en.wikipedia.org/wiki/Computability_theory recursion theory
